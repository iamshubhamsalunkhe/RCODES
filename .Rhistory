rules <- apriori(adv, parameter = list(supp = 0.5, conf = 0.9, target = "rules"))
rules <- apriori(adv, parameter = list(supp = 0.1, conf = 0.9, target = "rules"))
rules <- apriori(adv, parameter = list(supp = 0.1, conf = 0.8, target = "rules"))
rules <- apriori(adv, parameter = list(supp = 0.01, conf = 0.8, target = "rules"))
rules <- apriori(adv, parameter = list(supp = 0.001, conf = 0.8, target = "rules"))
rules <- apriori(adv, parameter = list(supp = 0.001, conf = 0.7, target = "rules"))
rules <- apriori(adv, parameter = list(supp = 0.0001, conf = 0.7, target = "rules"))
rules <- apriori(adv, parameter = list(supp = 0.00000001, conf = 0.7, target = "rules"))
rules <- apriori(adv, parameter = list(supp = 0.2, conf = 0.7, target = "rules"))
rules <- apriori(adv, parameter = list(supp = 0.6, conf = 0.7, target = "rules"))
rules <- apriori(adv, parameter = list(supp = 0.2, conf = 0.7, target = "rules"))
rules <- apriori(adv, parameter = list(supp = 0, conf = 0.7, target = "rules"))
?is.redundant()
?is.redundant
install.packages("ISLR")
library(ISLR)
names(Smarket)
dim(Smarket)
summary(Smarket)
?Smarket
cor(Smarket)
cor(Smarket[,-9])
head(Smarket)
attach(Smarket)
attach(Smarket)
attach(Smarket)
cor(Smarket[,-9])
head(Smarket)
attach(Smarket)
rm(list=ls()
rm(list=ls())
cor(Smarket)
library(ISLR)
cor(Smarket)
cor(Smarket[,-9])
head(Smarket)
attach(Smarket)
rm(list=ls())
head(Smarket)
attach(Smarket)
par(mfrow = c(1,1))
plot(Volume)
glm.fits = glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume, data = Smarket,family = binomial)
summary(glm.fits)
coef(glm.fits)
summary(glm.fits)$coef
summary(glm.fits)$coef[,4]
glm.probs = predict(glm.fits , type =  "response")
glm.probs[1:10]
contrasts(Direction)
?coef
glm.pred = rep("Down" , 1250)
glm.pred[glm.probs >.5] = "UP"
round(glm.probs[1:10] , 2)
glm.pred[1:10]
cor(Smarket[,-9])
(507 + 145 ) / 1250
mean(glm.pred == Direction)
train = (Year < 2005)
train = (Year < 2005)
Smarket.2005 = Smarket[!train,]
dim(Smarket)
dim(Smarket.2005)
Direction.2005 = Direction[!train]
glm.fits = glm(Direction ~ Lag1+Lag2+Lag3+Lag4+Lag5+Volume, data = Smarket , family = binomial , subset = train)
summary(glm.fits)
glm.probs = predict(glm.fits , Smarket.2005 , type = "response")
glm.pred =   rep("Down" , 252)
glm.pred[glm.probs >.5] = "Up"
table(glm.pred , Direction.2005)
mean(glm.pred == Direction.2005)
mean(glm.pred!=Direction.2005)
library(pROC)
install.packages("pROC")
library(pROC)
roccurve <- roc(Smarket.2005$Direction ~ glm.probs)
plot(roccurve)
auc(roccurve)
library(titanic)
install.packages("titanic")
?titanic
?Titanic
data("titanic_train")
data("titanic_test")
summary(titanic_train)
summary(titanic_test)
summary(titanic_train)
library(titanic)
?titanic
data("titanic_train")
data("titanic_test")
summary(titanic_train)
summary(titanic_test)
titanic_test$Survived <- NA
complete_data <- rbind(titanic_train , titanic_test)
str(complete_data)
is.na(complete_data)
sum(is.na(complete_data))
colSums(is.na(complete_data))
colSums(complete_data == '')
Mode <- function( x, na.rm = FALSE){
if(na.rm){
x = x[!is.na(x)]
}
ux <- unique(x)
return(ux[which.max(tabulate(match(x,ux)))])
}
x <- c(1:10 , 9 , 9 , 9 , 9 ,NA ,NA, NA)
x
x = x[!is.na(x)]
x
ux <- unique(x)
ux
match(x,ux)
tabulate(match(x ,ux))
which.max(tabulate(match(x, ux)))
ux[which.max(tabulate(match(x,ux)))]
x <- c(1:50 , 9 , 9 , 9 , 9 ,NA ,NA, NA)
x <- c(50:60 , 9 , 9 , 9 , 9 ,NA ,NA, NA)
x
x = x[!is.na(x)]
x
ux <- unique(x)
ux
match(x,ux)
match(x,ux)
tabulate(match(x ,ux))
which.max(tabulate(match(x, ux)))
ux[which.max(tabulate(match(x,ux)))]
x <- c(50:60 , 9 , 9 , 9 , 9 ,NA ,NA, NA)
x
x = x[!is.na(x)]
x
ux <- unique(x)
ux
match(x,ux)
tabulate(match(x ,ux))
which.max(tabulate(match(x, ux)))
ux[which.max(tabulate(match(x,ux)))]
x <- c(50:60 , 9 , 9 , 9 , 9 ,NA ,NA, NA)
x
x = x[!is.na(x)]
x
ux <- unique(x)
ux
match(x,ux)
tabulate(match(x ,ux))
which.max(tabulate(match(x, ux)))
ux[which.max(tabulate(match(x,ux)))]
Mode(complete_data$Embarked)
complete_data$Embarked[complete_data$Embarked==""] <- "S"
complete_data$Age[is.na(complete_data$Age)] <- median(complete_data$Age , na.rm = T)
library(dplyr)
titanic_data <- complete_data %>%
titanic_data <- complete_data %>% select(-c(Cabin,PassengerId,Ticket,Name))
titanic_data <- complete_data %>% select(-c(Cabin,PassengerId,Ticket,Name))
titanic_data1 <- select(complete_data , -c(Cabin , PassengerId,Ticket,Name))
head(titanic_data1)
sapply(complete_data , function(x) lenght(unique(X)))
sapply(complete_data , function(x) length(unique(X)))
sapply(complete_data , function(x) length(unique(x)))
head(titanic_data)
for(i in c("Survived" , "Pclass" , "Sex" , "Embarked")){
titanic_data[,i]=as.factor(titanic_data[,i])
}
head(titanic_data)
summary(titanic_data)
View(titanic_data)
library(dummies)
install.packages("dummies")
library(dummies)
titanic_data <- dummy.data.frame(titanic_data,
names=c("Pclass", "Sex" , "Embarked") ,
sep="_")
head(titanic_data)
dim(titanic_data)
train <- titanic_data[1:667,]
test <- titanic_data[668:889,]
titanic_data <- dummy.data.frame(titanic_data,
names=c("Pclass", "Sex" , "Embarked") ,
sep="_")
library(titanic)
data("titanic_train")
data("titanic_test")
summary(titanic_train)
summary(titanic_test)
titanic_test$Survived <- NA
complete_data <- rbind(titanic_train , titanic_test)
str(complete_data)
is.na(complete_data)
sum(is.na(complete_data))
colSums(is.na(complete_data))
colSums(complete_data == '')
Mode <- function( x, na.rm = FALSE){
if(na.rm){
x = x[!is.na(x)]
}
ux <- unique(x)
return(ux[which.max(tabulate(match(x,ux)))])
}
x <- c(50:60 , 9 , 9 , 9 , 9 ,NA ,NA, NA)
x
x = x[!is.na(x)]
x
ux <- unique(x)
ux
match(x,ux)
tabulate(match(x ,ux))
which.max(tabulate(match(x, ux)))
ux[which.max(tabulate(match(x,ux)))]
Mode(complete_data$Embarked)
complete_data$Embarked[complete_data$Embarked==""] <- "S"
complete_data$Age[is.na(complete_data$Age)] <- median(complete_data$Age , na.rm = T)
library(dplyr)
titanic_data <- complete_data %>% select(-c(Cabin,PassengerId,Ticket,Name))
titanic_data1 <- select(complete_data , -c(Cabin , PassengerId,Ticket,Name))
head(titanic_data1)
sapply(complete_data , function(x) length(unique(x)))
for(i in c("Survived" , "Pclass" , "Sex" , "Embarked")){
titanic_data[,i]=as.factor(titanic_data[,i])
}
head(titanic_data)
summary(titanic_data)
View(titanic_data)
library(dummies)
titanic_data <- dummy.data.frame(titanic_data,
names=c("Pclass", "Sex" , "Embarked") ,
sep="_")
head(titanic_data)
dim(titanic_data)
model0 <- glm(Pclassc~.,data = titanic_data , family = binomial , subset = train)
model0 <- glm(Pclass~.,data = titanic_data , family = binomial , subset = train)
model0 <- glm(Pclass_1~.,data = titanic_data , family = binomial , subset = train)
model0 <- glm(Pclass_1 ~ .,data = titanic_data , family = binomial , subset = train)
model0 <- glm(Pclass_1 ~ ., data = titanic_data , family = binomial , subset = train)
model0 <- glm(Pclass_1 ~ ., data = titanic_data , family = binomial )
summary(model0)
model0 <- glm(Pclass ~ ., data = titanic_data , family = binomial )
model0 <- glm(Pclass_1 + Pclass_2 + Pclass_3 ~ ., data = titanic_data , family = binomial )
summary(model0)
rm(list=ls())
data <- matrix(c(1:10, 21:30), nrow = 5, ncol = 4)
data
#average value of row
apply (data, 1, mean)
#average value of columns
apply (data, 2, mean)
data
#average value of row
apply (data, 1, mean)
#average value of columns
apply (data, 2, mean)
#sd value of row
apply (data, 1, sd)
#sd value of columns
apply (data, 2, sd)
#median value of row
apply (data, 1, median)
#median value of columns
apply (data, 2, median)
vec <- (1:4)
mat <- matrix(vec,2,2)
list_data <- list(vec, mat)
list_data
data <- list(x = 1:5, y = 6:10, z = 11:15)
data
lapply(data, mean)
lapply(data, median)
data <- list(x = 1:5, y = 6:10, z = 11:15)
data
lapply(data, mean)
sapply(data, mean)
sapply(data, range)
# arrays are matrices in more than 2 dimensions
a <- array(1:24, dim = c(3,4,2))
a
vec1 <- c(5, 9, 3)
vec2 <- c(10,11,12,13,14,15,16)
result <- array(c(vec1,vec2), dim = c(3,4,2))
result
age <- c(23,33,28,21,20,19,34)
gender <- c("m","m","m","f","f","f","m")
tapply(age, gender, mean)
tapply(gender,age,mean)
#load the datasets
library(datasets)
data()
data <- matrix(c(1:10, 21:30), nrow = 5, ncol = 4)
data
#average value of row
apply (data, 1, mean)
#average value of columns
apply (data, 2, mean)
#sd value of row
apply (data, 1, sd)
vec <- (1:4)
mat <- matrix(vec,2,2)
list_data <- list(vec, mat)
list_data
dim(data)
View(data)
## look at the data just an overview
##for load the train data
data <- read.csv("train.csv")
head(data)
summary(data)
colnames(data)
View(data)
str(data)
colSums(is.na(data))
dim(data)
##so missing values in are not that much so we can handle it by imputing mode if neccessary
## credit history was numeric as seen un structure of data we just made it as factor because
## credit history tells us whether it meets the guidelines or not
data$Credit_History <- as.factor(data$Credit_History)
## applying feature engineering for applicant and co applicant they both are telling the income
##we can convert them into household income
#imputing mode on na values
Mode <- function(x, na.rm = FALSE) {
if(na.rm){
x = x[!is.na(x)]
}
ux <- unique(x)
return(ux[which.max(tabulate(match(x, ux)))])
}
Mode(data$Credit_History, na.rm = T)
library(Hmisc)
data$Credit_History <- impute(data$Credit_History, Mode)
sum(is.na(data$Credit_History))
#imputing median on na values
## box plot of loanamount to detect outliers
boxplot(data$LoanAmount)
median(data$LoanAmount,na.rm = T)
data$LoanAmount <- impute(data$LoanAmount , median)
sum(is.na(data$LoanAmount))
### treating na values in loan_amount_term
#### this code will replac blank space with na values in data <- read.csv("train.csv",na.strings = c(""))
data <- read.csv("train.csv",na.strings = c(""))
colSums(is.na(data))
##Treating values Self_Employed
data$Self_Employed <- impute(data$Self_Employed, Mode)
##Treating values Gender
data$Gender <- impute(data$Gender, Mode)
##treating values Married
data$Married <- impute(data$Married, Mode)
##treating values Dependents
data$Dependents <- impute(data$Dependents, Mode)
## treating values Loan_Amoutn_term
data$Loan_Amount_Term <- impute(data$Loan_Amount_Term, median)
## checking for any missing values
colSums(is.na(data))
### comibining applicantsincome and coapplicant income into household
data$household <- data$ApplicantIncome + data$CoapplicantIncome
head(data)
summary(data)
### binning dependant columne
data$Dependents <- ifelse((data$Dependents == 0) ,0,1)
data$Dependents <- as.factor(data$Dependents)
head(data$Dependents)
## backup data
data_without_na <- data
##visualize the data and try to detect skewness and outliers
hist(log(data$household),50)
hist(log(data$Loan_Amount_Term),50)
median(data$household)
str(data)
library(corrplot)
corrplot(data)
g
drop(anov1)
View(data)
View(data)
View(data)
View(data_without_na)
setwd("~/Rcodes")
data <- read.csv("train.csv")
data <- read.csv("train.csv",na.strings = c(""))
colSums(is.na(data))
install.packages("ISLR")
library(ISLR)
set.seed(1)
train = sample(392,196)
?Auto
summary(Auto)
dim(Auto)
install.packages("boot")
attach(Auto)
lm.fit = lm(mpg ~ horsepower, data = Auto , subset = train)
summary(lm.fit)
E11 <- mean((mpg - predict(lm.fit , Auto))[-train]^2)
E11
lm.fit2 = lm(mpg ~ poly (horsepower , 2),data = Auto , subset = train)
summary(lm.fit2)
lm.fit3 = lm(mpg ~ poly(horsepower , 3), data = Auto , subset = train)
summary(lm.fit3)
E13 <- mean((mpg-predict(lm.fit3 , Auto))[-train]^2)
E13
E <- c(E11,E12,E13)
E12 <- mean((mpg-predict(lm.fit2 , Auto))[-train]^2)
E12
E <- c(E11,E12,E13)
E
mpg[1:5]
predict(lm.fit3 , Auto)[1:5]
(mpg-predict(lm.fit3 , Auto))[1:5]
-train[1:5]
(mpg-predict(lm.fit3 , Auto))[-train][1:5]
((mpg-predict(lm.fit3 , Auto))[-train]^2)[1:5]
mean(((mpg-predict(lm.fit3 , Auto))[-train]^2))[1:5]
mean(((mpg-predict(lm.fit3 , Auto))[-train]^2))
set.seed(2)
lm.fit_ = lm(mpg ~ horsepower, data = Auto , subset = train)
summary(lm.fit)
E11_ <- mean((mpg - predict(lm.fit_ , Auto))[-train]^2)
E11_
lm.fit_2 = lm(mpg ~ poly (horsepower , 2),data = Auto , subset = train)
E12_ <- mean((mpg-predict(lm.fit_2 , Auto))[-train]^2)
E12_
lm.fit_3 = lm(mpg ~ poly(horsepower , 3), data = Auto , subset = train)
summary(lm.fit_3)
E13_ <- mean((mpg-predict(lm.fit_3 , Auto))[-train]^2)
E13_
E_ <- c(E11_,E12_,E13_)
E_
Error <- cbind(E,E_)
Error
glm.fit = glm(mpg ~ horsepower , data = Auto)
coef(glm.fit)
lm.fit = lm(mpg~horsepower , data = Auto )
coef(lm.fit)
library(boot)
glm.fit = glm(mpg ~ horsepower , data = Auto )
cv.err$delta
cv.err = cv.glm(Auto , glm.fit) # no k is mentioned means it is running LOOOCV
cv.err$delta
cv.err$K
cv.error = rep (0,5)
cv.error
cv.error[i] = cv.glm(Auto , glm.fit)$delta[1]
for(i in 1:5){
glm.fit = glm(mpg ~ poly(horsepower , i ), data = Auto)
cv.error[i] = cv.glm(Auto , glm.fit)$delta[1]
}
cv.error
set.seed(17)
for (i in 1:10) {
glm.fit= glm(mpg ~ poly(horsepower , i ), data = Auto)
cv.error.10[i] = cv.glm(Auto , glm.fit , K = 10)$delta[1]
}
cv.error.10 = rep(0,10)
for (i in 1:10) {
glm.fit= glm(mpg ~ poly(horsepower , i ), data = Auto)
cv.error.10[i] = cv.glm(Auto , glm.fit , K = 10)$delta[1]
}
cv.error.10
?poly
?cv.glm
for (i in 1:10) {
glm.fit= glm(mpg ~ poly(horsepower , i ), data = Auto)
cv.error.10[i] = cv.glm(Auto , glm.fit , K = 20)$delta[1]
}
cv.error.10
library(MASS)
?iris
colnames(iris)
cor1 <- cor(iris$Sepal.Length , iris$Sepal.Width)
cor1
cor2 <- cor(iris$Petal.Length , iris$Petal.Width)
cor2
cor3 <- cor(iris$Petal.Length , iris$Sepal.Length)
cor3
cor4 <- cor(iris$Petal.Width ,iris$Sepal.Width)
cor4
summary(iris)
install.packages("class")
library(class)
cor_ <- c(cor1, cor2, cor3,cor4)
cor_
library(corrplot)
corrplot(iris)
library(corrplot[,-5])
corrplot(iris,[-5])
corrplot(iris)[-5]
normalize <- function(x)
{
num <- x - min(x)
denom <- max(x) - min(x)
return(num/denom)
}
iris_norm <- as.data.frame(lapply(iris[1:4], normalize))
summary(iris_norm)
set.seed(1234)
ind <- sample(2, nrow(iris) , replace = TRUE , prob = c(0.67 , 0.33))
table(ind)
iris.training <- iris[ind == 1,1:4]
iris.training
iris.testing <- iris[ind == 2,1:4]
iris.testing
iris.trainlabels <- iris[ind == 1 , 5]
iris.testlabels <- iris[ind == 2, 5]
iris.pred <- knn(train = iris.training ,
test = iris.testing,
cl = iris.trainlabels,
k = 3)
iris.pred
?knn
View(iris)
#?knn
iris.testlabels
sum(iris.pred == iris.testlabels)
mean(iris.pred == iris.testlabels)
table(iris.pred,iris.testlabels)
